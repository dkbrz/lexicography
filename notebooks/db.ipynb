{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dkbrz/GitHub/lexicography/languages/en_ru/en-ru.align'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '/home/dkbrz/GitHub/lexicography/languages/'\n",
    "\n",
    "lang1 = 'en'\n",
    "lang2 = 'ru'\n",
    "\n",
    "lang1_token = '{}{}_{}/{}_token.txt'.format(PATH, lang1, lang2, lang1)\n",
    "lang1_lemma = '{}{}_{}/{}_align.txt'.format(PATH, lang1, lang2, lang1)\n",
    "lang2_token = '{}{}_{}/{}_token.txt'.format(PATH, lang1, lang2, lang2)\n",
    "lang2_lemma = '{}{}_{}/{}_align.txt'.format(PATH, lang1, lang2, lang2)\n",
    "\n",
    "alignment = '{}{}_{}/{}-{}.align'.format(PATH, lang1, lang2, lang1, lang2)\n",
    "alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7282566, 107417)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang1_dict = defaultdict(int)\n",
    "k = 0\n",
    "for line in open(lang1_lemma):\n",
    "    phrase = line.strip().split()\n",
    "    for word in phrase:\n",
    "        lang1_dict[word] += 1\n",
    "        k += 1\n",
    "k, len(lang1_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6130822, 125310)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang2_dict = defaultdict(int)\n",
    "k = 0\n",
    "for line in open(lang2_lemma):\n",
    "    phrase = line.strip().split()\n",
    "    for word in phrase:\n",
    "        lang2_dict[word] += 1\n",
    "        k += 1\n",
    "k, len(lang2_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOD = set(['VERB', 'NOUN', 'ADV', 'ADJ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3165"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 0\n",
    "lang1_set = set()\n",
    "for i in sorted(lang1_dict, key=lang1_dict.get, reverse=True):\n",
    "    #print (i, lang1_dict[i])\n",
    "    data = i.split('_')\n",
    "    if lang1_dict[i] > 100 and data[1] in GOOD:\n",
    "        n += 1\n",
    "        lang1_set.update([i])\n",
    "        #print (i, lang1_dict[i])\n",
    "    #if n == 500:\n",
    "    #    break\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3564"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 0\n",
    "lang2_set = set()\n",
    "for i in sorted(lang2_dict, key=lang2_dict.get, reverse=True):\n",
    "    #print (i, lang1_dict[i])\n",
    "    data = i.split('_')\n",
    "    if lang2_dict[i] > 100 and data[1] in GOOD:\n",
    "        n += 1\n",
    "        lang2_set.update([i])\n",
    "        #print (i, lang1_dict[i])\n",
    "    #if n == 500:\n",
    "    #    break\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3165, 3564)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lang1_set), len(lang2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Kids can get pretty much anything they want in the yard , as long as they can afford it .\\n', 'kid_NOUN_0 can_AUX_1 get_VERB_2 pretty_ADV_0 much_ADJ_1 anything_NOUN_1 they_PRON_0 want_VERB_2 in_ADP_1 the_DET_0 yard_NOUN_0 ,_PUNCT_0 as_ADP_1 long_ADV_0 as_ADP_2 they_PRON_0 can_AUX_2 afford_VERB_0 it_PRON_0 ._PUNCT_0\\n', 'Дети могут достать во дворе почти всё что угодно до тех пор , пока могут себе это позволить .\\n', 'ребенок_NOUN_1 мочь_VERB_2 достать_VERB_0 в_ADP_0 двор_NOUN_0 почти_ADV_1 все_PRON_0 что_PRON_0 угодно_ADV_0 до_ADP_0 тот_DET_0 пора_NOUN_1 ,_PUNCT_0 пока_SCONJ_1 мочь_VERB_0 себя_PRON_0 это_PRON_0 позволить_VERB_0 ._PUNCT_0\\n', '0-0 1-1 2-2 3-5 5-7 5-8 6-6 8-3 9-10 10-4 11-12 12-13 13-13 14-13 15-13 16-14 17-15 17-17 18-16 19-18\\n')\n",
      "[(0, 0), (1, 1), (2, 2), (3, 5), (5, 7), (5, 8), (6, 6), (8, 3), (9, 10), (10, 4), (11, 12), (12, 13), (13, 13), (14, 13), (15, 13), (16, 14), (17, 15), (17, 17), (18, 16), (19, 18)]\n",
      "kid_NOUN_0 ребенок_NOUN_1\n",
      "can_AUX_1 мочь_VERB_2\n",
      "get_VERB_2 достать_VERB_0\n",
      "pretty_ADV_0 почти_ADV_1\n",
      "anything_NOUN_1 что_PRON_0\n",
      "anything_NOUN_1 угодно_ADV_0\n",
      "they_PRON_0 все_PRON_0\n",
      "in_ADP_1 в_ADP_0\n",
      "the_DET_0 тот_DET_0\n",
      "yard_NOUN_0 двор_NOUN_0\n",
      ",_PUNCT_0 ,_PUNCT_0\n",
      "as_ADP_1 пока_SCONJ_1\n",
      "long_ADV_0 пока_SCONJ_1\n",
      "as_ADP_2 пока_SCONJ_1\n",
      "they_PRON_0 пока_SCONJ_1\n",
      "can_AUX_2 мочь_VERB_0\n",
      "afford_VERB_0 себя_PRON_0\n",
      "afford_VERB_0 позволить_VERB_0\n",
      "it_PRON_0 это_PRON_0\n",
      "._PUNCT_0 ._PUNCT_0\n"
     ]
    }
   ],
   "source": [
    "files = [open(lang1_token), open(lang1_lemma), open(lang2_token), open(lang2_lemma), open(alignment)]\n",
    "\n",
    "for lines in zip(*files):\n",
    "    #assert len(lines[0].split()) == len(lines[1].split()) \n",
    "    print (lines)\n",
    "    align_phrase = [tuple(int(x) for x in i.split('-')) for i in lines[-1].split()]\n",
    "    print (align_phrase)\n",
    "    lang1_phrase = lines[1].split()\n",
    "    lang2_phrase = lines[3].split()\n",
    "    for i in align_phrase:\n",
    "        print (lang1_phrase[i[0]], lang2_phrase[i[1]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1259738, 4246635, 1812399)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [open(lang1_token), open(lang1_lemma), open(lang2_token), open(lang2_lemma), open(alignment)]\n",
    "\n",
    "over100_both = 0\n",
    "under100_both = 0\n",
    "diff = 0\n",
    "for lines in zip(*files):\n",
    "    #assert len(lines[0].split()) == len(lines[1].split()) \n",
    "    #print (lines)\n",
    "    align_phrase = [tuple(int(x) for x in i.split('-')) for i in lines[-1].split()]\n",
    "    #print (align_phrase)\n",
    "    lang1_phrase = lines[1].split()\n",
    "    lang2_phrase = lines[3].split()\n",
    "    for i in align_phrase:\n",
    "        #print (lang1_phrase[i[0]], lang2_phrase[i[1]])\n",
    "        if lang1_phrase[i[0]] in lang1_set and lang2_phrase[i[1]] in lang2_set:\n",
    "            over100_both += 1\n",
    "        elif lang1_phrase[i[0]] not in lang1_set and lang2_phrase[i[1]] not in lang2_set:\n",
    "            under100_both += 1\n",
    "        else:\n",
    "            diff += 1\n",
    "over100_both, under100_both, diff\n",
    "#(5508537, 513065, 1371246)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17212423067694962, 0.5802387340389891, 0.2476370352840613)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = over100_both + under100_both +diff\n",
    "over100_both/s, under100_both/s, diff/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  passwd='password',\n",
    "  database=\"test_bilingual\")\n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 1\n",
    "for i in sorted(lang1_set):\n",
    "    data = i.split('_')\n",
    "    sense = int(data[-1])\n",
    "    pos = data[-2]\n",
    "    lemma = '_'.join(data[:-2])\n",
    "    #print (lemma, pos, data)\n",
    "    if pos == 'PUNCT':\n",
    "        pass\n",
    "    else:\n",
    "        mycursor.execute('INSERT INTO dictionary (lang, lemma, pos, sense) VALUES (%s, %s, %s, %s)',\n",
    "                        (lang, lemma, pos, sense))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 2\n",
    "for i in sorted(lang2_set):\n",
    "    data = i.split('_')\n",
    "    sense = int(data[-1])\n",
    "    pos = data[-2]\n",
    "    lemma = '_'.join(data[:-2])\n",
    "    #print (lemma, pos, data)\n",
    "    if pos == 'PUNCT':\n",
    "        pass\n",
    "    else:\n",
    "        mycursor.execute('INSERT INTO dictionary (lang, lemma, pos, sense) VALUES (%s, %s, %s, %s)',\n",
    "                        (lang, lemma, pos, sense))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lang1_set, lang2_set\n",
    "del lang1_dict, lang2_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute('SELECT * FROM dictionary WHERE lang=1')\n",
    "result = mycursor.fetchall()\n",
    "lang1_dict = {}\n",
    "for i in result:\n",
    "    lang1_dict['{}_{}_{}'.format(i[2], i[3], i[4])] = i[0]\n",
    "del result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute('SELECT * FROM dictionary WHERE lang=2')\n",
    "result = mycursor.fetchall()\n",
    "lang2_dict = {}\n",
    "for i in result:\n",
    "    lang2_dict['{}_{}_{}'.format(i[2], i[3], i[4])] = i[0]\n",
    "del result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3165, 3564)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lang1_dict), len(lang2_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "733"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang1_dict['do_VERB_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycursor.execute('SELECT * FROM examples ORDER BY id DESC LIMIT 1')\n",
    "mycursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_word(item):\n",
    "    data = i.split('_')\n",
    "    sense = int(data[-1])\n",
    "    pos = data[-2]\n",
    "    lemma = '_'.join(data[:-2])\n",
    "    return lemma, pos, sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf7150fa14c4cd5b22be5b9cc370250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files = [open(lang1_token), open(lang1_lemma), open(lang2_token), open(lang2_lemma), open(alignment)]\n",
    "\n",
    "k = 1\n",
    "for lines in tqdm(zip(*files)):\n",
    "    left_token = lines[0].strip()\n",
    "    right_token = lines[2].strip()\n",
    "    lang1_phrase = lines[1].split()\n",
    "    lang2_phrase = lines[3].split()\n",
    "    align_phrase = [tuple(int(x) for x in i.split('-')) for i in lines[-1].split()]\n",
    "    \n",
    "    tot = 0\n",
    "    for i in align_phrase:\n",
    "        left = lang1_phrase[i[0]]\n",
    "        right = lang2_phrase[i[1]]\n",
    "        if left in lang1_dict and right in lang2_dict:\n",
    "            mycursor.execute(\"INSERT INTO alignment (id_sent, id_left, id_right, id_lemma_left, id_lemma_right) \\\n",
    "             VALUES (%s, %s, %s, %s, %s)\", (k, i[0], i[1], lang1_dict[left], lang2_dict[right],))\n",
    "            tot += 1\n",
    "    \n",
    "    if tot > 0:\n",
    "        mycursor.execute(\"INSERT INTO examples (sent_left, sent_right, lang_left, lang_right) VALUES (%s, %s, 1, 2)\",\n",
    "                    (left_token, right_token,))\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute('SELECT DISTINCT id_sent FROM alignment')\n",
    "set_ids = set(i[0] for i in mycursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "594751"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute('SELECT DISTINCT id FROM examples')\n",
    "set_ids = set(i[0] for i in mycursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "594751"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
